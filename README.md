# Cricket-Modelling-Project
Code for my project predicting the 2019 WC


This is a major statistical-prediction project I'm working on ahead of the ICC (men's) Cricket World Cup in England starting on May 30. The aim---and I've already made major progress towards this end, thankfully---is to develop a sophisticated prediction model in an attempt to predict the World Cup (or, as a preliminary ambition, to predict some of the group-stage games). Very soon, I will commence getting up a website advertising my model and its predictions with some pretty graphics.

The process started a few months ago, beginning with a lot of scraping---in particular, several years worth of data on ODI cricket matches from Cricinfo, using its wonderful Statsguru searchable database (http://stats.espncricinfo.com/ci/engine/stats/index.html), plus historic player rankings data from the old ICC rankings page (http://www.relianceiccrankings.com/), and data on historic team rankings obtained miscellaneously. This all involved several Python web-scraping scripts (see repository for code), and was at times rather painstaking. The harder part, though, was to integrate this data into a spreadsheet where each row is a match, with columns for both basic metadata (teams, data) and for the richer data-types I had harvested ((normalised) ranking, proxies for batting-strength and bowling-strength, win margin, plus some important categorical data: home/away/neutral, batfirst_day/batfirst_night/batsecond_day/batsecond_night). Eventually, I managed to put all the matches, with all the attendant data, in one nice .csv file (see repository).

Initially, I began with five years of data, then I expanded it out to 8 when I found that I couldn't get a satisfying logistic regression going (this may also have had to do with the encoding of my categorical variables, not that I understood this issue at the time). I may have time to add another two or three years, but there are also some advantages to recency and the sample size I have achieved is respectable enough.

At this stage, I have used a subset of the data I have collected (ignoring all the tied matches, and ignoring my margin of victory data) to do a logistic regression. This has allowed me not only to identify the relative strength of each of the general factors involved in deciding ODI match outcomes, but I now have my first prediction model also. On my test data, I've achieved a prediction-accuracy rate of 0.65, which I'm pretty happy with (though this result involves regression on a couple of variables that only come into play after the toss is known). In theory, I should be able to do better than that predicting games in just one environment (England), rather than generally, because I should be able to integrate the rate of success of team X in English conditions.

One subtle, interesting result of this process is that, at least if we can trust my proxies and sample size, a team's batting strength matters more than its bowling strength.... by quite a margin. It may suggest that good bowlers tend to have less of an outsize impact than good batsmen in ODI matches (see repository for more).

I am not sure if I'll have time to fit a model that deals with more than two outcomes (tie, small win/loss, moderate win/loss, big win/loss) before the World Cup begins. However, as I suggested, I will try to integrate England-specific data into the 'final model' somehow.

**Update on 3 April**
I finally have gotten around to committing and pushing the data files I created using the scripts that I had already uploaded, along with the program that does all the necessary data-fiddling to ultimately generate the logistic regression (log_regression.py). 

The other major update is that I have now used the fitted log-regression model to generate a balance of probabilities for Team X winning versus Y for every match in the World Cup (e.g. for game 1, at The Oval, my model generated England: 67%, South Africa: 33% (I think I am not going to worry so much about ties because that outcome occurs in less than 1% of ODI games; in any case, the ratio of victory-likelihood should not change even if you include some nonzero probability for tie as a third outcome)). Later this week, I hope to present all my results in an elegant format on a Wordpress blog I will set up for the purpose. I will also generate a bunch of graphs and plots to serve as visual aids/ornaments/stimuli/aids to understanding.

The other thing I am currently working on---and the results of this process will appear on that website also--- is a Monte Carlo simulation using the probability estimates for each game that I've developed. Basically, the idea is that I will run >1000 trials of the World Cup and see how often each team comes 1st, 2nd, 3rd, 4th. Now, I in fact already know what this ought to spit out in terms of the ultimate order of 1st to 4th (1: England, 2: India, 3: NZ, 4: SA... or 1: ENG, 2: AUS, 3: IND, 4: NZ with some rigging of the results to crudely incorporate Australia's recent form) from doing a crude deterministic pairwise-comparison simulation (by 'crude deterministic pairwise-comparison' I mean you simulate the WC according to the rule that the team that wins in each contest is the one with the higher probability of success (and ignoring ties)). However, the benefit of the Monte Carlo simulation I am working on is that it will allow me to get the actual probability estimate of any of the teams winning the tournament (or coming 2nd, 3rd, etc) by generating how many times in all the trials they do so (if England wins the WC in 500 of 1000 trials, then that tells me that Prob(England wins the WC) = 50% according to my model). It's just a way of generating the whole-tournament probability distribution.   
